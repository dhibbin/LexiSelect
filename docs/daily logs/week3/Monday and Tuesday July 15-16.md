# Monday and Tuesday July 15-16

Tasks completed
- Settings can now be given to the singleton of the LLMService and they are checked before being used, ensuring that invalid fetch requests aren't made
	- Tried to make this system better by tying setting value and rules together, however this wouldn't let me use the rule functions within the LLMSettingsWrapper, so I discarded and reverted most of the changes I made on Monday
- The LLMService singleton can now return prompts from the LLM server as a LlamaInterface, this interface was autogenerated by an [online tool](https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://json2ts.vercel.app/&ved=2ahUKEwiI8rqciqyHAxXrU0EAHUKhBwwQFnoECAYQAQ&usg=AOvVaw19ogJ5o9z1DAUGCSsmETzb) however it needed to be modified so that it didnt use any `any` types
- Spent most of Tuesday trying to change the layout of the page to have the text boxes at the bottom of the page and to have a main content window in the middle
- Fought with Vuetify's grids system and decided it would be easier for the text boxes to be within `v-app-bar` elements instead and switched the component to use those instead
- Installed the `gsap` module for tweening so I could make the different tab options disappear depending on if you are looking at the input or output window
- Started to investigate ways that I could create a pan-able and zoom-able tree on a canvas so that you can explore the paths you have taken the generation over time